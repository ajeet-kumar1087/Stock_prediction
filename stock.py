# -*- coding: utf-8 -*-
"""Stock.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TXBJV1Y8_ES-fb2msnoKweLrsIOeQ8PG
"""

import math
import pandas_datareader as web
import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from keras.models import Sequential
from keras.layers import Dense, LSTM
import matplotlib.pyplot as plt
plt.style.use('fivethirtyeight')

from google.colab import drive
drive.mount('/content/drive')

#Get stock
df=web.DataReader('ACN', data_source='yahoo', start='2010-01-01', end ='2020-01-01')
df

df.shape



#visualisation
plt.figure(figsize=(16,8))
plt.title('closing')
plt.plot(df['Close'])
plt.xlabel('Date')
plt.ylabel('Close price')
plt.show

#dataframe with close
data = df.filter(['Close'])
dataset=data.values # to numpy array
training_data_len = math.ceil(len(dataset)* .8) # 80 percent data to be trained

training_data_len #number of training data sets

#scale the data
scaler = MinMaxScaler(feature_range=(0,1))
scaled_data = scaler.fit_transform(dataset) #transform the data for scaling
scaled_data

#creating the training data set
#create the scaled training
train_data=scaled_data[0:training_data_len, :]
#split the data into x and y train
x_train = []
y_train = []

for i in range(60,len(train_data)): 
  x_train.append(train_data[i-60:i, 0]) #start sixty values is used to train the data set
  y_train.append(train_data[i, 0])  #sixtyfirst value in the training data
  if i<=62:
   print(x_train)
   print(y_train)
   print()

#convert the x and y to numpy 
x_train, y_train = np.array(x_train), np.array(y_train)

#reshape the data
x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1],1))
x_train.shape

#build lstm model
model = Sequential()
model.add(LSTM(50,return_sequences=True, input_shape=(x_train.shape[1], 1)))
model.add(LSTM(50, return_sequences= False))
model.add(Dense(25))
model.add(Dense(1))

model.compile(optimizer='adam', loss='mean_squared_error')

#train model
model.fit(x_train, y_train, batch_size=1, epochs=1)

#create test data
test_data= scaled_data[training_data_len-60: , :]
x_test = []
y_test = dataset[training_data_len:, :]
for i in range(60,len(test_data)) :
  x_test.append(test_data[i-60:i,0])

#convert data to numpy
x_test = np.array(x_test)

x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1],1 ))

#get the models predicted price
predictions = model.predict(x_test)
predictions = scaler.inverse_transform(predictions)

#get the rmse
rmse= np.sqrt(np.mean( predictions - y_test )**2)
rmse

#plot the data
train = data[:training_data_len]
valid = data[training_data_len: ]
valid['Predictions'] = predictions
plt.figure(figsize=(16,8))
plt.title('Model')
plt.xlabel('Date', fontsize=18)
plt.ylabel('Close price', fontsize=18)
plt.plot(train['Close'])
plt.plot(valid[['Close','Predictions']])
plt.legend(['Train', 'Val', 'Predictions'], loc='lower right')
plt.show()

#show the vaid and predicted prices
valid

